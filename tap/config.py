VICUNA_PATH = "/media/d1/huggingface.co/models/lmsys/vicuna-13b-v1.5"
LLAMA_PATH = "/media/d1/huggingface.co/models/meta-llama/Llama-2-7b-chat-hf"

LLAMA_7B_PATH = "/media/d1/huggingface.co/models/meta-llama/Llama-2-7b-chat-hf"
LLAMA_13B_PATH = "/media/d1/huggingface.co/models/meta-llama/Llama-2-13b-chat-hf"
LLAMA_70B_PATH = "/media/d1/huggingface.co/models/meta-llama/Llama-2-70b-chat-hf"
GEMMA_2B_PATH = "google/gemma-2b-it"
GEMMA_7B_PATH = "google/gemma-7b-it"
MISTRAL_7B_PATH = "/media/d1/huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.2"
MIXTRAL_7B_PATH = "/media/d1/huggingface.co/models/mistralai/Mixtral-8x7B-Instruct-v0.1"
R2D2_PATH = "cais/zephyr_7b_r2d2"
LLAMA3_8B_PATH = "/media/d1/huggingface.co/models/meta-llama/Meta-Llama-3-8B-Instruct"
LLAMA3_70B_PATH = "/media/d1/huggingface.co/models/meta-llama/Meta-Llama-3-70B-Instruct"


ATTACK_TEMP = 1
TARGET_TEMP = 0
ATTACK_TOP_P = 0.9
TARGET_TOP_P = 1

# Increase the above allow more streams in parallel
# Decrease it to reduce the memory requirement 
MAX_PARALLEL_STREAMS = 3
